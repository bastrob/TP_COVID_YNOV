{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projet de groupe 1\n",
    "BOUSQUIE Johan (préparation et la structuration des données)\n",
    "\n",
    "ROBERT Bastien (scripts: recupération des données, fonction nb, preparation tweets, map et graph interactifs )\n",
    "\n",
    "ROBERT Simon (Analyse et Visualisation des données)\n",
    "\n",
    "SORBY Franck (Analyse et visualisation des données)\n",
    "\n",
    "# Projet de groupe 1 : Récolte de données sur la pandémie du Covid-19\n",
    "\n",
    "\n",
    "[Lien vers le git](https://github.com/bastrob/TP_COVID_YNOV)\n",
    "\n",
    "\n",
    "### Introduction\n",
    "L'objectif de ce projet était de récolter, structurer et analyser des données en relation avec la pandémie de Covid 19.\n",
    "\n",
    "Avec cet objectif, nous avons donc décidé d'orienter notre analyse autour des problématiques suivantes:\n",
    "\n",
    "* Le facteur humain a-t-il un impact sur l’évolution du covid ?\n",
    "\n",
    "* L'opinion et le comportement des gens ont-ils un impact sur l’évolution du COVID ?\n",
    "\n",
    "* Existe-t-il un lien entre le ressenti des gens et l’évolution de la pandémie ?\n",
    "\n",
    "\n",
    "## Partie 1: Récolte des données\n",
    "\n",
    "Afin de répondre à nos problématiques, un ensemble de données doivent être récoltées.\n",
    "\n",
    "Dans un premier temps, nous allons récolter l'ensemble des données relatives à l'évolution de l'épidémie en France, départements par départements.\n",
    "\n",
    "Ensuite il nous fallait récolter un ensemble de réactions afin d'évaluer l'impact moral de la pandémie.\n",
    "De plus nous avons recensés tous les événements marquants pendant les confinements (couvre-feu\n",
    "\n",
    "### Scrapping évolution Covid 19\n",
    "\n",
    "Récupération des données libres (voir licence dans script coronaviusAPI_france) du gouvernement par le biais d'une API. Les données étaient accessibles par département depuis le début du premier confinement au format json. (Il fallait aussi relancer régulierement le script car les données étaient mises à jour tous les jours à 8 heures).\n",
    "Il a donc fallu créer un csv pour chaque département avec les informations que nous avions ciblés.\n",
    "\n",
    "### Preparation évolution Covid 19\n",
    "\n",
    "Dans le script de préparation nous avons commencé par aggréger l'ensemble des départements dans un seul et même fichier csv.\n",
    "    Nous avons ensuite ajouté plusieurs colonnes comme la région, la population, les coordonnées lat long parceque nous avons fait le choix de visualiser l'évolution du Covid par région.\n",
    "    Toutes ces informations n'étant pas disponibles de base dans le fichier brut, nous avons dû effectuer des recherches pour les récupérer.\n",
    "   Pour récupérer ces coordonnées, nous avons utilisé l'API Nominatim d'OpenStreetMap. Pour certaines visualisations (voir fn.create_map_france_2), nous avons récuperé des fichiers au format shapefile et avons manipulé des GeoDataFrame.\n",
    "    Lorsque le processus de préparation est terminé, le fichier csv est sauvegardé dans le dossier /datasets_cleaned.\n",
    "    \n",
    "### Scrapping Twitter\n",
    "\n",
    "L'objectif était de récupérer des tweets provenant des deux confinements, pour comprendre l'état d'esprits des français et leur ressenti par rapport à ces deux périodes.\n",
    "Pour récupérer des tweets du premier confinement nous avons dû récupérer les tweets à partir des ID, (https://github.com/calciu/COVID19-LockdownFr), et passer par l'API de Twitter en utlisant tweepy. La constitution des datasets fut longue car Twitter limite le nombre de requêtes.\n",
    "Pour le second confinement, nous avons utilisé l'API Stream de Twitter qui permettait de récupérer en temps réel les tweets postés. Nous avons configurés une liste d'hashtags pour sélectionner uniquement ceux qui nous intéressaient.\n",
    "### Preparation Twitter\n",
    "Nous avons appliqué plusieurs traitements, nettoyage du tweet, utilisation de regex, extraction des émojis et des hashtags, supression des stop_words et caractères spéciaux. De plus, nous avons ajouté une colonne qui montre la popularité d'un tweet, en comptant le nombre de fois que ce tweet a été retweeté.\n",
    "Les licences sont renseignées dans les scripts où dans les dossiers contenant les données.\n",
    "Nous avons recueillis 170k de tweets du premiers confinement (environ 30k en enlevant les RT) et 9k du second confinement.\n",
    "Les fichiers raw json sont stockés en local sur un DD, Github limite le stockage des fichiers volumineux (format LFS)\n",
    "\n",
    "\n",
    "## Partie 2: Analyse des données\n",
    "\n",
    "\n",
    "Afin de répondre à notre problématique, nous avons décidé de mettre en relation les données liées à l'évolution de la pandémie et les dates clés de la pandémie en France, avec les mesures majeures prises par le gouvernement.\n",
    "\n",
    "Le développement de l'analyse se trouve dans le notebook covid à la racine du repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Au final, lors de cette étude, il nous apparait que sur les chiffres et le nombre de cas, il n'y a pas de réelle évolution. La première et la seconde vague se ressemblent, de même que les confinements. \n",
    "Le changement se trouve au niveau de la relation qu'à la population avec le confinement. Cela se voit principalement à travers nos nuages de mots, la thématique générale à totalement changée. Principalement à cause des évènements qui marquaient l'actualité.\n",
    "\n",
    "### Axes d'amélioration\n",
    "\n",
    "* Nombre de cas recensés vs la prise de conscience réelle des personnes\n",
    "* Impact du confinement à comparer avec celui du couvrefeu\n",
    "* Impact des tests massif comparé au couvrefeu\n",
    "* Le port du masque a-il influencé le nombre de cas de COVID-19\n",
    "* Différence commerce ouvert entre le 1er et le 2e confinement\n",
    "* Mesure plus poussée des tweets: Analyse de sentiments, analyse des emojis, des hastags, les gens tweets ils plus pendant le confinement que d'ordinaire? Observer les tweets des gens sur des dates précises (une mesure mise en place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
